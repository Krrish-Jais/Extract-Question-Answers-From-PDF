{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krrish-Jais/Extract-Question-Answers-From-PDF/blob/main/PDF_Q_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOK0ikCo5EQa"
      },
      "outputs": [],
      "source": [
        "# Installing all the required modules\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install faiss-cpu\n",
        "!pip install PyPDF2\n",
        "!pip install -U langchain-openai\n",
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fLs1iTLi53vm"
      },
      "outputs": [],
      "source": [
        "# Imporing the modules and library\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
        "import tiktoken\n",
        "import os\n",
        "from langchain_openai import OpenAI\n",
        "import langchain\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEAQxozy6l6H"
      },
      "outputs": [],
      "source": [
        "# Using Environment Variables to place of our API key safely\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "# Initializing a language model (LLM) using OpenAI's API.\n",
        "llm = OpenAI(temperature=0, model_name=\"text-davinci-003\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lCcv20am7MGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8154394f-3c0d-48e6-d3ca-6572254ccccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mounting our google drive to google collab so that we can import our pdf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir= \"/content/gdrive/My Drive/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Location of the pdf file in my drive.\n",
        "reader = PdfReader('/content/gdrive/My Drive/Big Mac Index.pdf')"
      ],
      "metadata": {
        "id": "FyP55PmzcBT_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "T9nAhXGL9_SD"
      },
      "outputs": [],
      "source": [
        "# Reading data from the file and putting it into variable 'raw_text'\n",
        "raw_text = ''\n",
        "for i, page in enumerate(reader.pages):\n",
        "  content=page.extract_text()\n",
        "  if content:\n",
        "    raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9bUyyNZM-tDB"
      },
      "outputs": [],
      "source": [
        "# We need to split the text that we read into smaller chunk so that during information retreival it shouldn't hit the token size limit.\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hLXHE49K_qlz"
      },
      "outputs": [],
      "source": [
        "# Downloading embeddings frm OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eZ5UotMjAQGu"
      },
      "outputs": [],
      "source": [
        "# To create an index that allows you to efficiently search for similar texts based on their embeddings.\n",
        "docsearch = langchain.vectorstores.faiss.FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XiTWrCZxE21_"
      },
      "outputs": [],
      "source": [
        "# To load a question-answering (QA) chain with specific configurations.\n",
        "chain = load_qa_chain(OpenAI(temperature=0.7),chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "byipr2_wWkES"
      },
      "outputs": [],
      "source": [
        "# To make a query Of MCQ Question\n",
        "query = \"Generate 5 MCQ Questions with answers from the document\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "response = chain.run(input_documents=docs,question=query)\n",
        "# Creating a txt file of the response received from OpenAI\n",
        "if not os.path.exists(\"PDF\"):\n",
        "  os.mkdir(\"PDF\")\n",
        "with open(f\"PDF/PDF_MCQ\", \"w\", encoding='UTF-8') as f:\n",
        "  f.write(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2o8XoyC9eX2Q"
      },
      "outputs": [],
      "source": [
        "# To make a query Of True and False Question\n",
        "query = \"Generate 5 True and False Questions with answers from the document\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "response = chain.run(input_documents=docs,question=query)\n",
        "# Creating a txt file of the response received from OpenAI\n",
        "if not os.path.exists(\"PDF\"):\n",
        "  os.mkdir(\"PDF\")\n",
        "with open(f\"PDF/PDF_TorF\", \"w\", encoding='UTF-8') as f:\n",
        "  f.write(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ThaLC9XQgo5x"
      },
      "outputs": [],
      "source": [
        "# To make a query Of One word Question\n",
        "query = \"Generate 5 One Word Questions with answers from the document\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "response = chain.run(input_documents=docs,question=query)\n",
        "# Creating a txt file of the response received from OpenAI\n",
        "if not os.path.exists(\"PDF\"):\n",
        "  os.mkdir(\"PDF\")\n",
        "with open(f\"PDF/PDF_One_Word\", \"w\", encoding='UTF-8') as f:\n",
        "  f.write(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up a web application using Streamlit and then exposing it to the internet using localtunnel.\n",
        "!wget -q -O - ipv4.icanhazip.com\n",
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "CAtcS8B9kOrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pqPQs0e9kmgX"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cgaw7nxog4DMO2L1uwmLKNFCH_m4YJXu",
      "authorship_tag": "ABX9TyOXOqYWXBTwaqU1OEi3CP2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}